initdb -D "D:/pri"
initdb -D "D:/sec"


pg_ctl -D D:\pri -o "-p 5433" -l d:\pri\logfile start


>psql -p 5433 -d postgres -c "CREATE ROLE replicator with REPLICATION LOGIN PASSWORD 'repl_pass';"

pg_basebackup -D d:\sec -Fp -Xs -P -R -h 127.0.0.1 -U replicator -p 5433

pg_ctl -D D:\sec -o "-p 5435" -l d:\sec\logfile start

psql -p 5433 -d postgres 

(In another cmd)

psql -p 5435 -d postgres

--------------------------------------
5433 - 
select * from pg_stat_replication;
5435
select pg_is_in_recovery();
-------------------------------------
Create table in primary

Check in secondary
---------------------------------------------------------------------------



create or replace procedure proc_create_customer_rental_payment(
p_first_name text,p_last_name text, p_email text,p_address_id int, 
p_inventory_id int, p_store_is int,
p_staff_id int,p_amount numeric
)
Language plpgsql
as $$
DECLARE
    v_customer_id INT;
    v_rental_id INT;
BEGIN
  Begin
    INSERT INTO customer (store_id, first_name, last_name, email, address_id, active, create_date)
    VALUES (p_store_is,p_first_name,p_last_name,p_email,p_address_id, 1, CURRENT_DATE)
    RETURNING customer_id INTO v_customer_id;
 
    INSERT INTO rental (rental_date, inventory_id, customer_id, staff_id)
    VALUES (CURRENT_TIMESTAMP, p_inventory_id, v_customer_id, p_staff_id)
    RETURNING rental_id INTO v_rental_id;
    
    INSERT INTO payment (customer_id, staff_id, rental_id, amount, payment_date)
    VALUES (v_customer_id, p_staff_id, 100000, p_amount, CURRENT_TIMESTAMP);
  Exception when others then
    raise notice 'Transaction failed %',sqlerrm;
  End;
END; 
$$;

select * from customer order by customer_id  desc

call proc_create_customer_rental_payment ('Ram','Som','ram_som@gmail.com',1,1,1,1,-10)

--loop through all the films and update the rental rate by +1 for teh films when rental count < 5


create or replace procedure proc_update_rental_rate()
language plpgsql
as $$
declare
  rec record;
  cur_film_rent_count cursor for
  select f.film_id, f.rental_rate, count(r.rental_id) as rental_count 
  from film f left join inventory i on f.film_id = i.film_id
  left join rental r on i.inventory_id = r.inventory_id
  group by f.film_id, f.rental_rate;
Begin
  open cur_film_rent_count;

  Loop
  	Fetch cur_film_rent_count into rec;
	exit when not found;

	if rec.rental_count < 5 then
	   update film set rental_rate= rental_rate +1
	   where film_id =  rec.film_id;

	   raise notice 'updated file  with id % . The new rental rate is %',rec.film_id,rec.rental_rate+1;
	end if;
end loop;
close cur_film_rent_count;
end;
$$;

call proc_update_rental_rate();
----------------------------------------------------------------------------
















Cursors 
Write a cursor to list all customers and how many rentals each made. Insert these into a summary table.

Using a cursor, print the titles of films in the 'Comedy' category rented more than 10 times.

Create a cursor to go through each store and count the number of distinct films available, and insert results into a report table.

Loop through all customers who haven't rented in the last 6 months and insert their details into an inactive_customers table.
--------------------------------------------------------------------------

Transactions 
Write a transaction that inserts a new customer, adds their rental, and logs the payment – all atomically.

Simulate a transaction where one update fails (e.g., invalid rental ID), and ensure the entire transaction rolls back.

Use SAVEPOINT to update multiple payment amounts. Roll back only one payment update using ROLLBACK TO SAVEPOINT.

Perform a transaction that transfers inventory from one store to another (delete + insert) safely.

Create a transaction that deletes a customer and all associated records (rental, payment), ensuring referential integrity.
----------------------------------------------------------------------------

Triggers
Create a trigger to prevent inserting payments of zero or negative amount.

Set up a trigger that automatically updates last_update on the film table when the title or rental rate is changed.

Write a trigger that inserts a log into rental_log whenever a film is rented more than 3 times in a week.
------------------------------------------------------------------------------


create table rental_tax_log (
    rental_id int,
    customer_name text,
    rental_date timestamp,
    amount numeric,
    tax numeric
);

select * from rental_tax_log
do $$
declare
    rec record;
    cur cursor for
        select r.rental_id, 
               c.first_name || ' ' || c.last_name as customer_name,
               r.rental_date,
               p.amount
        from rental r
        join payment p on r.rental_id = p.rental_id
        join customer c on r.customer_id = c.customer_id;
begin
    open cur;

    loop
        fetch cur into rec;
        exit when not found;

        insert into rental_tax_log (rental_id, customer_name, rental_date, amount, tax)
        values (
            rec.rental_id,
            rec.customer_name,
            rec.rental_date,
            rec.amount,
            rec.amount * 0.10
        );
    end loop;

    close cur;
end;
$$;
-------------------------------------------------------------
do $$
declare
    rental_record record;
    rental_cursor cursor for
        select r.rental_id, c.first_name, c.last_name, r.rental_date
        from rental r
        join customer c on r.customer_id = c.customer_id
        order by r.rental_id;
begin
    open rental_cursor;

    loop
        fetch rental_cursor into rental_record;
        exit when not found;

        raise notice 'rental id: %, customer: % %, date: %',
                     rental_record.rental_id,
                     rental_record.first_name,
                     rental_record.last_name,
                     rental_record.rental_date;
    end loop;

    close rental_cursor;
end;
$$;
---------------------------------------------------------------------



create or replace function Update_Audit_log()
returns trigger 
as $$
declare 
   col_name text := TG_ARGV[0];
   tab_name text := TG_ARGV[1];
   o_value text;
   n_value text;
begin
    EXECUTE FORMAT('select ($1).%I::TEXT', COL_NAME) INTO O_VALUE USING OLD;
    EXECUTE FORMAT('select ($1).%I::TEXT', COL_NAME) INTO N_VALUE USING NEW;
	if o_value is distinct from n_value then
		Insert into audit_log(table_name,field_name,old_value,new_value,updated_date) 
		values(tab_name,col_name,o_value,n_value,current_Timestamp);
	end if;
	return new;
end;
$$ language plpgsql





create trigger trg_log_customer_email_Change
after update
on customer
for each row
execute function Update_Audit_log('last_name','customer');

update customer set last_name = 'Smith' where customer_id = 1
--------------------------------------------------------------------------------
create table audit_log
(audit_id serial primary key,
table_name text,
field_name text,
old_value text,
new_value text,
updated_date Timestamp default current_Timestamp)

create or replace function Update_Audit_log()
returns trigger 
as $$
begin
	Insert into audit_log(table_name,field_name,old_value,new_value,updated_date) 
	values('customer','email',OLD.email,NEW.email,current_Timestamp);
	return new;
end;
$$ language plpgsql


create trigger trg_log_customer_email_Change
before update
on customer
for each row
execute function Update_Audit_log();

drop trigger trg_log_customer_email_Change on customer
drop table audit_log;
select * from customer order by customer_id

select * from audit_log
update customer set email = 'mary.smiths@sakilacustomer.org' where customer_id = 1

create or replace function Update_Audit_log()
returns trigger 
as $$
declare 
   col_name text := TG_ARGV[0];
   tab_name text := TG_ARGV[1];
   o_value text;
   n_value text;
begin
    o_value := row_to_json(old);
	n_value := row_to_json(new);
	if o_value is distinct from n_value then
		Insert into audit_log(table_name,field_name,old_value,new_value,updated_date) 
		values(tab_name,col_name,o_value,n_value,current_Timestamp);
	end if;
	return new;
end;
$$ language plpgsql




--EXECUTE FORMAT('select ($1).%I::TEXT', COL_NAME) INTO O_VALUE USING OLD
--EXECUTE FORMAT('select ($1).%I::TEXT', COL_NAME) INTO N_VALUE USING NEW

create trigger trg_log_customer_email_Change
after update
on customer
for each row
execute function Update_Audit_log('email','customer');


----------------------------------------------------------



12 May 2025

/*
Transactions : Concurrency and Locking
ACID Properties of Transactions:
1. Atomicity
2. Consistency
3. Isolation
4. Durability

Why are Transactions Important?

Basic Transaction Commands
1. BEGIN
2. COMMIT
3. ROLLBACK
4. SAVEPOINT
*/

CREATE TABLE tbl_bank_accounts
(
account_id SERIAL PRIMARY KEY,
account_name VARCHAR(100),
balance NUMERIC(10, 2)
);

INSERT INTO tbl_bank_accounts
(account_name, balance)
VALUES
('Alice', 5000.00),
('Bob', 3000.00);

SELECT * FROM tbl_bank_accounts;

-- Perform Transaction/Tran
BEGIN;

UPDATE tbl_bank_accounts
SET balance = balance - 500
WHERE account_name = 'Alice';

UPDATE tbl_bank_accounts
SET balance = balance + 500
WHERE account_name = 'Bob';

COMMIT;

SELECT * FROM tbl_bank_accounts;

-- Introducing Error (Rollback)
BEGIN;

UPDATE tbl_bank_accounts
SET balance = balance - 500
WHERE account_name = 'Alice';

UPDATE tbl_bank_account
SET balance = balance + 500
WHERE account_name = 'Bob';

ROLLBACK;

SELECT * FROM tbl_bank_accounts;

-- Savepoints: Partial Rollback
-- Example 1
BEGIN;

UPDATE tbl_bank_accounts
SET balance = balance - 100
WHERE account_name = 'Alice';

SAVEPOINT after_alice;

UPDATE tbl_bank_account
SET balance = balance + 100
WHERE account_name = 'Bob';

ROLLBACK TO after_alice;

UPDATE tbl_bank_accounts
SET balance = balance + 100
WHERE account_name = 'Bob';

COMMIT;

SELECT * FROM tbl_bank_accounts;

-- Example 2
BEGIN;

UPDATE tbl_bank_accounts
SET balance = balance - 100
WHERE account_name = 'Alice';

SAVEPOINT after_alice;

UPDATE tbl_bank_account
SET balance = balance + 100
WHERE account_name = 'Bob';

ROLLBACK TO after_alice;

-- Auto Commit without BEGIN
UPDATE tbl_bank_accounts
SET balance = balance + 100
WHERE account_name = 'Bob';

-- Errors -> Rollback or Commit

COMMIT;

SELECT * FROM tbl_bank_accounts;

ABORT;

-- Raising Notice
BEGIN;
DO $$
DECLARE
  current_balance NUMERIC;
BEGIN
SELECT balance INTO current_balance
FROM tbl_bank_accounts
WHERE account_name = 'Alice';

IF current_balance >= 1500 THEN
   UPDATE tbl_bank_accounts SET balance = balance - 4500 WHERE account_name = 'Alice';
   UPDATE tbl_bank_accounts SET balance = balance + 4500 WHERE account_name = 'Bob';
ELSE
   RAISE NOTICE 'Insufficient Funds!';
   ROLLBACK;
END IF;
END;
$$;

-- UPDATE inside BEGIN TRAN
START/BEGIN TRANSACTION;
UPDATE tbl_bank_accounts
SET balance = balance + 500
WHERE account_name = 'Alice';

SELECT * FROM tbl_bank_accounts;
-- At this point, change is not committed yet.
COMMIT; -- Change is permanently saved.
-- Open a different psql instance and check the table records.

-- Inside BEGIN OR START TRANSACTION, nothing is auto-committed.

-- BEGIN, UPDATES, NOT COMMIT -> changes are not saved unless you do a commit.

-- This is auto-committed by default.
UPDATE tbl_bank_accounts SET balance = balance - 4500 WHERE account_name = 'Alice';

-- Auto-Commit
/*
In PSQL, autocommit is ON by default.
MySQL -> SET autocommit = 1; //Enable

Stage 1 - C1
Stage 2 -> S1
Stage 3 -> Rollback to S1, C2
*/

-- Best Practices for Transactions
/*
1. Keep transactions short -> Improve Concurreny and Reduce Locking
2. Use savepoints for complex flows -> Safer partial rollbacks
3. Log failed trans for audits -> Traceability and Degugging
4. Avoid user inputs during transactions -> Prevent long trans
5. In production code, always wrap db ops inside try-catch with explicit commit and rollback.
*/

/*
Concurrency
PostgreSQL handles concurrency using:
1. MVCC (Multi-Version Concurrency Control):
MVCC allows multiple versions of the same data (rows) to exist temporarily,
so readers and writers don't block each other.

Readers don't block writers and Writers don't block readers.

Example 1: Read While Someone is Updating
-- Trans A
*/
BEGIN;
UPDATE products
SET price = 500
WHERE id = 1;

-- Trans B
BEGIN;
SELECT price FROM products 
WHERE id = 1;

-- 450

-- Examples for MVCC
/*
1. 
User A: Reads
User B: Updates

2. 
1000 users check balance (reads)
10 users perform withdrawals (writes)

Read Committed
-- Trans A
BEGIN;
UPDATE products
SET price = 500
WHERE id = 1;

-- Trans B
BEGIN;
SELECT price FROM products
WHERE id = 1;
-- 450

Repeatable Read
-- Trans A
BEGIN ISOLATION LEVEL REPEATABLE READ;
SELECT price FROM products
WHERE id = 1; -- 450

-- Trans B
BEGIN;
UPDATE products
SET price = 500 WHERE id = 1;
COMMIT;

-- Trans A
SELECT price FROM products
WHERE id = 1; -- 450
COMMIT;
*/



2. Isolation Levels : 4 --> Concurrency
   1. READ UNCOMMITTED -> PSQL not supported
   2. READ COMMITTED -> Default; MVCC
   MVCC is ACID-Compliant.
   Read Committed is powered by MVCC.
   3. Repeatable Read -> Ensures repeatabe reads
   4. Serializable -> Full isolation (safe but slow, no dirty reads, no lost updates, no repeatable reads, no phantom reads)
   

Problems without proper Concurrency Control:
1. Inconsistent Reads/Dirty Reads: Reading Uncommitted data from another transaction, which might later disappear.
Transaction A updates a row but doesn’t commit yet.
Transaction B reads that updated row.
Transaction A rolls back the update.
Now Transaction B has read data that never officially existed — that’s a dirty read.

Why Dirty Reads Happen:
They occur in databases running at low isolation levels, particularly:
Read Uncommitted isolation level → allows dirty reads.
Higher isolation levels like Read Committed, Repeatable Read, or Serializable
prevent dirty reads but come with performance trade-offs (like more locks or slower concurrency).

2. Lost Update
Transaction A reads a record.
Transaction B reads the same record.
Transaction A updates and writes it back.
Transaction B (still holding the old value) writes back its version, overwriting A’s changes.

-- Trans A
*/
BEGIN;
SELECT balance FROM Accounts
WHERE id = 1;  -- 100
-- Thinks to add 50

-- Trans B
BEGIN;
SELECT balance FROM Accounts
WHERE id = 1; -- 100
-- Thinks to sub 30
UPDATE Accounts
SET balance = 70
WHERE id = 1;
COMMIT;

-- Trans A
UPDATE Accounts
SET balance = 150
WHERE id = 1;
COMMIT;

/*
Solutions to Avoid Lost Updates:
1. Pessimistic Locking (Explicit Locks)
Lock the record when someone reads it, so no one else can read or write until the lock is released.
Example: SELECT ... FOR UPDATE in SQL.
Prevents concurrency but can reduce performance due to blocking.
2. Optimistic Locking (Versioning)
Common and scalable solution.
Each record has a version number or timestamp.
When updating, you check that the version hasn’t changed since you read it.
If it changed, you reject the update (user must retry).
Example:
UPDATE products
SET price = 100, version = version + 1
WHERE id = 1 AND version = 3; --3
3. Serializable Isolation Level
In database transactions, using the highest isolation level (SERIALIZABLE) can prevent lost updates.
But it's heavier and can cause performance issues (due to more locks or transaction retries).

Which Solution is Best?
For web apps and APIs: Optimistic locking is often the best balance (fast reads + safe writes).
For critical financial systems: Pessimistic locking may be safer.

Inconsistent reads/read anomalies
1. Dirty Read
2. Non-Repeatable Read
Transaction A reads a row, -- 100
Transaction B updates and commits the row, then --90
Transaction A reads the row again and sees different data.

-- Trans A
*/
BEGIN;
SELECT balance FROM Accounts
WHERE id = 1; -- 1000

-- Trans B
UPDATE Accounts
SET baalnce = balance - 200
WHERE id = 1;
COMMIT;

-- Trans A
BEGIN;
SELECT balance FROM Accounts
WHERE id = 1; -- 1000-200=800

-- Phatom Read
-- SELECT * FROM orders WHERE amount > 1000; returns 5 rows.
-- Another transaction inserts a new order with amount 1200 and commits — now re-running the
-- query returns 6 rows.

-- Trans A
BEGIN;
SELECT * FROM Accounts
WHERE balance > 500;
-- 1 row

-- Trans B
BEGIN;
INSERT INTO Accounts
(id, balance)
VALUES
(2, 600);
COMMIT;

-- Trans A
SELECT * FROM Accounts
WHERE balance > 500;
-- 2 rows
-- A phatom new row appeared!


-- Step 1: Set up a sample table
CREATE TABLE Accounts
(
ID INT PRIMARY KEY,
balance INT
);

INSERT INTO Accounts
VALUES
(1, 1000);

-- Step 2 : Trans A
BEGIN TRANSACTION;
UPDATE Accounts
SET balance = 0 
WHERE id = 1;

-- Step 3: Trans B
-- Allow Dirty Read
SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;
BEGIN TRANSACTION;
SELECT balance FROM Accounts
WHERE id = 1; -- User B sees 0 as balance

-- Step 4: Trans A decides to Rollback
ROLLBACK;
-- balance = 1000 for User A but 0 for User B

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

12 May 2025: Transactions and Concurrency Task

1️⃣ Question:
In a transaction, if I perform multiple updates and an error happens in the third statement, but I have not used SAVEPOINT, what will happen if I issue a ROLLBACK?
Will my first two updates persist?

2️⃣ Question:
Suppose Transaction A updates Alice’s balance but does not commit. Can Transaction B read the new balance if the isolation level is set to READ COMMITTED?

3️⃣ Question:
What will happen if two concurrent transactions both execute:
UPDATE tbl_bank_accounts SET balance = balance - 100 WHERE account_name = 'Alice';
at the same time? Will one overwrite the other?

4️⃣ Question:
If I issue ROLLBACK TO SAVEPOINT after_alice;, will it only undo changes made after the savepoint or everything?

5️⃣ Question:
Which isolation level in PostgreSQL prevents phantom reads?

6️⃣ Question:
Can Postgres perform a dirty read (reading uncommitted data from another transaction)?

7️⃣ Question:
If autocommit is ON (default in Postgres), and I execute an UPDATE, is it safe to assume the change is immediately committed?

8️⃣ Question:
If I do this:

BEGIN;
UPDATE accounts SET balance = balance - 500 WHERE id = 1;
-- (No COMMIT yet)
And from another session, I run:

SELECT balance FROM accounts WHERE id = 1;
Will the second session see the deducted balance?

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
13 May 2025

/*
Locking Mechanism
PostgreSQL automatically applies locks, but you can control them manually when needed.

Types of Locks

MVCC VS Locks
MVCC allows readers and writers to work together without blocking.
Locks are needed when multiple writers try to touch the same row or table.

Simple Rule of Locks
Readers don’t block each other.
Writers block other writers on the same row.


Row-Level Locking (Default Behavior) / Implicit Lock
Two Users updating the same row
-- Trans A
*/
BEGIN;
UPDATE products
SET price = 500
WHERE id = 1;
-- Trans A holds a lock on row id = 1

-- Trans B
BEGIN;
UPDATE products
SET price = 600
WHERE id = 1;

/*
Result:
B waits until A commits or rollbacks
Row Level Locking
*/

-- Table-Level Locks / Explicit Table Lock
1. ACCESS SHARE -- select
-- Allows reads and writes

2. ROW SHARE
-- SELECT ... FOR UPDATE -> lock the selected row for later update

BEGIN;	
LOCK TABLE products
IN ACCESS SHARE MODE;
-- Allows other SELECTS, even INSERT/DELETE at the same time.

BEGIN;
LOCK TABLE products
IN ROW SHARE MODE;
-- SELECT .. FOR UPDATE, reads are allowed, conflicting row locks are blocked, writes allowed

3. EXCLUSIVE
-- Blocks writes (INSERT, UPDATE, DELETE) but allows reads (SELECT)

BEGIN;
LOCK TABLE products
IN EXCLUSIVE MODE;

4. ACCESS EXCLUSIVE  -- Most agressive lock 
-- Blocks everything, Used by ALTER TABLE, DROP TABLE, TRUNCATE, 
-- Internally used by DDL.


-- A
BEGIN;
LOCK TABLE products IN ACCESS EXCLUSIVE MODE;
-- Table is now fully locked!

-- B
SLEECT * FROM products;
-- B will wait until A commits or rollbacks.

-- Explicit Row Locks --> SELECT ... FOR UPDATE
-- A
BEGIN;
SELECT * FROM products
WHERE id = 1
FOR UPDATE;
-- Row id = 1 is now locked

-- B
BEGIN;
UPDATE products
SET price = 700
WHERE id = 1;
-- B is blocked until A finishes.

-- SELECT ... FOR UPDATE locks the row early so no one can change it midway.
-- Banking, Ticket Booking, Inventory Management Systems
/*
A deadlock happens when:
Transaction A waits for B
Transaction B waits for A
They both wait forever.

-- Trans A
*/
BEGIN;
UPDATE products
SET price = 500
WHERE id = 1;
-- A locks row 1

-- Trans B
BEGIN;
UPDATE products
SET price = 600
WHERE id = 2;
-- B locks row 2

-- Trans A
UPDATE products
SET price = 500
WHERE id = 2;
-- A locks row 2 (already locked by B)

-- Trans B
UPDATE products
SET price = 600
WHERE id = 1
--B locks row 1 (already locked by A)

/*
psql detects a deadlock
ERROR: deadlock detected
It automatically aborts a transaction to resolve deadlock.
*/

-- Advisory Lock / Custom Locks
-- Get a lock with ID 12345
SELECT pg_advisory_lock(12345);

-- critical ops

-- Releas the lock
SELECT pg_advisory_unlock(12345);

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

13 May 2025 - Task
1. Try two concurrent updates to same row → see lock in action.
2. Write a query using SELECT...FOR UPDATE and check how it locks row.
3. Intentionally create a deadlock and observe PostgreSQL cancel one transaction.
4. Use pg_locks query to monitor active locks.
5. Explore about Lock Modes.

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------